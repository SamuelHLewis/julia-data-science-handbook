{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156c703d",
   "metadata": {},
   "source": [
    "# Data Wrangling with DataFrames.jl\n",
    "Data wrangling is a core part of any data science project, and it makes life a lot easier if we can quickly and easily manipulate tabular data. The `DataFrames.jl` package provides the `DataFrame` type to hold tabular data, and numerous functions to operate on the data. It is also tightly integrated with other data science packages in Julia, such as `gadfly.jl` for visualization, and `GLM.jl` for statistical modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f282f",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "## Installing the DataFrames.jl and CSV.jl Packages\n",
    "Before we can use the `DataFrames.jl` package, we need to install it. We will also install the `CSV.jl` package to read CSV files from disk, the `DataFramesMeta.jl` package to provide some more intuitive functions for working with DataFrames, and the `Pipe.jl` package to string multiple commands together in one call. To install these packages, follow these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d4a57",
   "metadata": {},
   "source": [
    "1. Open the Julia REPL\n",
    "2. Type `]` to enter the package manager\n",
    "3. Type `add DataFrames` to install the DataFrames package\n",
    "4. Type `add CSV` to install the CSV package\n",
    "5. Type `add DataFramesMeta` to install the DataFramesMeta package\n",
    "6. Type `add Pipe` to install the Pipe package\n",
    "7. Press CTRL-C to exit the package manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad4c46",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdf179",
   "metadata": {},
   "source": [
    "Once you have installed these packages, load them into this notebook environment through the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9baf8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using DataFramesMeta\n",
    "using Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ba6ae",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "For this tutorial, we will be using the COVID-19 dataset from Our World in Data, which contains data on case rates, death rates and vaccination rates for almost all countries across the course of the COVID-19 pandemic:\n",
    "1. Navigate to the Our World in Data COVID-19 page [here](https://github.com/owid/covid-19-data/tree/master/public/data)\n",
    "2. Scroll down to the start of the README (underneath the list of folders and files in the repo)\n",
    "3. Click on the `CSV` link next to the title `Download our complete COVID-19 dataset`\n",
    "4. Once the data has downloaded, move it into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572c68a",
   "metadata": {},
   "source": [
    "# Creating DataFrames\n",
    "There are two ways to create DataFrames:\n",
    "1. Create a DataFrame from scratch using existing vectors\n",
    "2. Load data from disk into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9a888",
   "metadata": {},
   "source": [
    "## Creating DataFrames From Scratch\n",
    "DataFrames can be created from scratch, by first assigning values to vectors, and then constructing a DataFrame that holds all of these vectors as columns. If we want the same value to be repeated for all rows in a column, we can just pass one value when creating the DataFrame, and it will be repeated the correct number of times to fill all rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbecfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>fruit</th><th>stock</th><th>on_offer</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th><th title=\"Bool\">Bool</th></tr></thead><tbody><tr><th>1</th><td>Apple</td><td>200.0</td><td>0</td></tr><tr><th>2</th><td>Banana</td><td>175.0</td><td>0</td></tr><tr><th>3</th><td>Clementine</td><td>120.0</td><td>0</td></tr><tr><th>4</th><td>Damson</td><td>50.0</td><td>0</td></tr><tr><th>5</th><td>Elderberry</td><td>44.0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& fruit & stock & on\\_offer\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Bool\\\\\n",
       "\t\\hline\n",
       "\t1 & Apple & 200.0 & 0 \\\\\n",
       "\t2 & Banana & 175.0 & 0 \\\\\n",
       "\t3 & Clementine & 120.0 & 0 \\\\\n",
       "\t4 & Damson & 50.0 & 0 \\\\\n",
       "\t5 & Elderberry & 44.0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\n",
       "─────┼───────────────────────────────\n",
       "   1 │ Apple         200.0     false\n",
       "   2 │ Banana        175.0     false\n",
       "   3 │ Clementine    120.0     false\n",
       "   4 │ Damson         50.0     false\n",
       "   5 │ Elderberry     44.0     false"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_names = [\"Apple\", \"Banana\", \"Clementine\", \"Damson\", \"Elderberry\"]\n",
    "fruit_numbers = [200, 175, 120, 50, 44]\n",
    "df = DataFrame(\n",
    "    fruit = fruit_names,\n",
    "    stock = convert.(Float64, fruit_numbers),\n",
    "    on_offer = false\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e9849",
   "metadata": {},
   "source": [
    "Note that as the DataFrame is created, the type of each column is inferred from the values. If you want to specify a type for a column (e.g. `Float64` instead of `Int64`), you need to broadcast the `convert()` function across all elements of the vector within the call to the DataFrame constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1999f",
   "metadata": {},
   "source": [
    "## Creating DataFrames Row-by-Row\n",
    "We can also create a empty DataFrame and fill it row-by-row. This makes use of the `push!()` function which changes the DataFrame in-place. The new row is specified as a tuple, where the elements are in the same order as the columns in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7abd78fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m Input \u001b[0m\u001b[1m Squared \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64   \u001b[0m\n",
      "─────┼────────────────\n",
      "   1 │     1        1\n",
      "   2 │     2        4\n",
      "   3 │     3        9\n",
      "   4 │     4       16\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame(Input=Int[], Squared=Int[])\n",
    "inputs = 1:4\n",
    "for i in inputs\n",
    "    push!(df, (i, i^2))\n",
    "end\n",
    "println(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4e047",
   "metadata": {},
   "source": [
    "We can also pass a dict to `push!()`, where the keys match the column names of the DataFrame. This means that we don't have to worry about the order of the columns in the DataFrame that we are adding to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "091d17c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m Input \u001b[0m\u001b[1m Squared \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64   \u001b[0m\n",
      "─────┼────────────────\n",
      "   1 │     1        1\n",
      "   2 │     2        4\n",
      "   3 │     3        9\n",
      "   4 │     4       16\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame(Input=Int[], Squared=Int[])\n",
    "inputs = 1:4\n",
    "for i in inputs\n",
    "    push!(df, Dict(\"Squared\"=>i^2, \"Input\"=>i)) # note that column order is reversed, but this is handled\n",
    "end\n",
    "println(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2c486",
   "metadata": {},
   "source": [
    "**NOTE**: constructing a DataFrame row-by-row is much less efficient than constructing it all at once, so bear this in mind when working with large DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294fb4e",
   "metadata": {},
   "source": [
    "## Creating DataFrames From A CSV File\n",
    "We can also create a DataFrame from a CSV file, by using the `CSV` package and specifying `DataFrame` as the sink (the second argument):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8f72b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created for COVID dataset\n"
     ]
    }
   ],
   "source": [
    "covid = CSV.read(\"owid-covid-data.csv\", DataFrame)\n",
    "println(\"DataFrame created for COVID dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d8082",
   "metadata": {},
   "source": [
    "# Extracting DataFrame Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c074f",
   "metadata": {},
   "source": [
    "## DataFrame Dimensions\n",
    "To get the number of rows and columns in a DataFrame, we can use the `size()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c0a8f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208111, 67)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bf528",
   "metadata": {},
   "source": [
    "## DataFrame Column Names\n",
    "To get the name of each column in a DataFrame, we can use the `names()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f406d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67-element Vector{String}:\n",
       " \"iso_code\"\n",
       " \"continent\"\n",
       " \"location\"\n",
       " \"date\"\n",
       " \"total_cases\"\n",
       " \"new_cases\"\n",
       " \"new_cases_smoothed\"\n",
       " \"total_deaths\"\n",
       " \"new_deaths\"\n",
       " \"new_deaths_smoothed\"\n",
       " \"total_cases_per_million\"\n",
       " \"new_cases_per_million\"\n",
       " \"new_cases_smoothed_per_million\"\n",
       " ⋮\n",
       " \"cardiovasc_death_rate\"\n",
       " \"diabetes_prevalence\"\n",
       " \"female_smokers\"\n",
       " \"male_smokers\"\n",
       " \"handwashing_facilities\"\n",
       " \"hospital_beds_per_thousand\"\n",
       " \"life_expectancy\"\n",
       " \"human_development_index\"\n",
       " \"excess_mortality_cumulative_absolute\"\n",
       " \"excess_mortality_cumulative\"\n",
       " \"excess_mortality\"\n",
       " \"excess_mortality_cumulative_per_million\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053dd173",
   "metadata": {},
   "source": [
    "We can also filter the column names that are returned by `names()` based on their element type, or use a regex to match on the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ec999a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"location\"]\n",
      "[\"total_cases\", \"new_cases\", \"new_cases_smoothed\", \"total_cases_per_million\", \"new_cases_per_million\", \"new_cases_smoothed_per_million\"]\n"
     ]
    }
   ],
   "source": [
    "println(names(covid, String))\n",
    "println(names(covid, r\"cases\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2e0f4",
   "metadata": {},
   "source": [
    "Finally, we can use the `Not()` operator to exclude column names from being returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66998916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66-element Vector{String}:\n",
       " \"continent\"\n",
       " \"location\"\n",
       " \"date\"\n",
       " \"total_cases\"\n",
       " \"new_cases\"\n",
       " \"new_cases_smoothed\"\n",
       " \"total_deaths\"\n",
       " \"new_deaths\"\n",
       " \"new_deaths_smoothed\"\n",
       " \"total_cases_per_million\"\n",
       " \"new_cases_per_million\"\n",
       " \"new_cases_smoothed_per_million\"\n",
       " \"total_deaths_per_million\"\n",
       " ⋮\n",
       " \"cardiovasc_death_rate\"\n",
       " \"diabetes_prevalence\"\n",
       " \"female_smokers\"\n",
       " \"male_smokers\"\n",
       " \"handwashing_facilities\"\n",
       " \"hospital_beds_per_thousand\"\n",
       " \"life_expectancy\"\n",
       " \"human_development_index\"\n",
       " \"excess_mortality_cumulative_absolute\"\n",
       " \"excess_mortality_cumulative\"\n",
       " \"excess_mortality\"\n",
       " \"excess_mortality_cumulative_per_million\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(covid, Not(:iso_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d62a8a",
   "metadata": {},
   "source": [
    "## Viewing the Top and Bottom\n",
    "We can view the top of a DataFrame using the `first()` function. This is especially useful for inspecting data after we import it, to get an idea of what the columns contain. By default this only shows us the first entry, but we can specify the number of entries that we want to view. For large DataFrames, only the first few columns will be shown, and a message will be printed to say how many columns have been left out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c8ddc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 67 columns (omitted printing of 60 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th><th>new_cases</th><th>new_cases_smoothed</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-24</td><td>5.0</td><td>5.0</td><td><em>missing</em></td></tr><tr><th>2</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-25</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>3</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-26</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>4</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-27</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>5</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-28</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases & new\\_cases & new\\_cases\\_smoothed & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64? & Float64? & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & AFG & Asia & Afghanistan & 2020-02-24 & 5.0 & 5.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & AFG & Asia & Afghanistan & 2020-02-25 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t3 & AFG & Asia & Afghanistan & 2020-02-26 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t4 & AFG & Asia & Afghanistan & 2020-02-27 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & AFG & Asia & Afghanistan & 2020-02-28 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×67 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location    \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_cases \u001b[0m\u001b[1m n\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ AFG       Asia       Afghanistan  2020-02-24          5.0        5.0 \u001b[90m  \u001b[0m ⋯\n",
       "   2 │ AFG       Asia       Afghanistan  2020-02-25          5.0        0.0 \u001b[90m\u001b[0m\n",
       "   3 │ AFG       Asia       Afghanistan  2020-02-26          5.0        0.0 \u001b[90m\u001b[0m\n",
       "   4 │ AFG       Asia       Afghanistan  2020-02-27          5.0        0.0 \u001b[90m\u001b[0m\n",
       "   5 │ AFG       Asia       Afghanistan  2020-02-28          5.0        0.0 \u001b[90m  \u001b[0m ⋯\n",
       "\u001b[36m                                                              61 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(covid, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074dbc42",
   "metadata": {},
   "source": [
    "Similarly, we can use the `last()` function to view the bottom of the DataFrame, and specify the number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9800839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 67 columns (omitted printing of 60 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th><th>new_cases</th><th>new_cases_smoothed</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>ZWE</td><td>Africa</td><td>Zimbabwe</td><td>2022-08-09</td><td>256490.0</td><td>3.0</td><td>12.429</td></tr><tr><th>2</th><td>ZWE</td><td>Africa</td><td>Zimbabwe</td><td>2022-08-10</td><td>256492.0</td><td>2.0</td><td>9.857</td></tr><tr><th>3</th><td>ZWE</td><td>Africa</td><td>Zimbabwe</td><td>2022-08-11</td><td>256513.0</td><td>21.0</td><td>9.857</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases & new\\_cases & new\\_cases\\_smoothed & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64? & Float64? & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & ZWE & Africa & Zimbabwe & 2022-08-09 & 256490.0 & 3.0 & 12.429 & $\\dots$ \\\\\n",
       "\t2 & ZWE & Africa & Zimbabwe & 2022-08-10 & 256492.0 & 2.0 & 9.857 & $\\dots$ \\\\\n",
       "\t3 & ZWE & Africa & Zimbabwe & 2022-08-11 & 256513.0 & 21.0 & 9.857 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×67 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_cases \u001b[0m\u001b[1m new_\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String   \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ ZWE       Africa     Zimbabwe  2022-08-09     256490.0        3.0       ⋯\n",
       "   2 │ ZWE       Africa     Zimbabwe  2022-08-10     256492.0        2.0\n",
       "   3 │ ZWE       Africa     Zimbabwe  2022-08-11     256513.0       21.0\n",
       "\u001b[36m                                                              61 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last(covid, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba5cc8",
   "metadata": {},
   "source": [
    "If we want to view all of the rows and/or columns, we can use the `show()` function and set the `allrows` or `allcols` arguments to `true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aefe2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m208111×67 DataFrame\u001b[0m\n",
      "\u001b[1m    Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location    \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_cases \u001b[0m\u001b[1m new_cases_smoothed \u001b[0m\u001b[1m total_deaths \u001b[0m\u001b[1m new_deaths \u001b[0m\u001b[1m new_deaths_smoothed \u001b[0m\u001b[1m total_cases_per_million \u001b[0m\u001b[1m new_cases_per_million \u001b[0m\u001b[1m new_cases_smoothed_per_million \u001b[0m\u001b[1m total_deaths_per_million \u001b[0m\u001b[1m new_deaths_per_million \u001b[0m\u001b[1m new_deaths_smoothed_per_million \u001b[0m\u001b[1m reproduction_rate \u001b[0m\u001b[1m icu_patients \u001b[0m\u001b[1m icu_patients_per_million \u001b[0m\u001b[1m hosp_patients \u001b[0m\u001b[1m hosp_patients_per_million \u001b[0m\u001b[1m weekly_icu_admissions \u001b[0m\u001b[1m weekly_icu_admissions_per_million \u001b[0m\u001b[1m weekly_hosp_admissions \u001b[0m\u001b[1m weekly_hosp_admissions_per_million \u001b[0m\u001b[1m total_tests \u001b[0m\u001b[1m new_tests \u001b[0m\u001b[1m total_tests_per_thousand \u001b[0m\u001b[1m new_tests_per_thousand \u001b[0m\u001b[1m new_tests_smoothed \u001b[0m\u001b[1m new_tests_smoothed_per_thousand \u001b[0m\u001b[1m positive_rate \u001b[0m\u001b[1m tests_per_case \u001b[0m\u001b[1m tests_units \u001b[0m\u001b[1m total_vaccinations \u001b[0m\u001b[1m people_vaccinated \u001b[0m\u001b[1m people_fully_vaccinated \u001b[0m\u001b[1m total_boosters  \u001b[0m\u001b[1m new_vaccinations \u001b[0m\u001b[1m new_vaccinations_smoothed \u001b[0m\u001b[1m total_vaccinations_per_hundred \u001b[0m\u001b[1m people_vaccinated_per_hundred \u001b[0m\u001b[1m people_fully_vaccinated_per_hundred \u001b[0m\u001b[1m total_boosters_per_hundred \u001b[0m\u001b[1m new_vaccinations_smoothed_per_million \u001b[0m\u001b[1m new_people_vaccinated_smoothed \u001b[0m\u001b[1m new_people_vaccinated_smoothed_per_hundred \u001b[0m\u001b[1m stringency_index \u001b[0m\u001b[1m population \u001b[0m\u001b[1m population_density \u001b[0m\u001b[1m median_age \u001b[0m\u001b[1m aged_65_older \u001b[0m\u001b[1m aged_70_older \u001b[0m\u001b[1m gdp_per_capita \u001b[0m\u001b[1m extreme_poverty \u001b[0m\u001b[1m cardiovasc_death_rate \u001b[0m\u001b[1m diabetes_prevalence \u001b[0m\u001b[1m female_smokers \u001b[0m\u001b[1m male_smokers \u001b[0m\u001b[1m handwashing_facilities \u001b[0m\u001b[1m hospital_beds_per_thousand \u001b[0m\u001b[1m life_expectancy \u001b[0m\u001b[1m human_development_index \u001b[0m\u001b[1m excess_mortality_cumulative_absolute \u001b[0m\u001b[1m excess_mortality_cumulative \u001b[0m\u001b[1m excess_mortality \u001b[0m\u001b[1m excess_mortality_cumulative_per_million \u001b[0m\n",
      "\u001b[1m        \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64?           \u001b[0m\u001b[90m Float64?     \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64?            \u001b[0m\u001b[90m Float64?                \u001b[0m\u001b[90m Float64?              \u001b[0m\u001b[90m Float64?                       \u001b[0m\u001b[90m Float64?                 \u001b[0m\u001b[90m Float64?               \u001b[0m\u001b[90m Float64?                        \u001b[0m\u001b[90m Float64?          \u001b[0m\u001b[90m Float64?     \u001b[0m\u001b[90m Float64?                 \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Float64?                  \u001b[0m\u001b[90m Float64?              \u001b[0m\u001b[90m Float64?                          \u001b[0m\u001b[90m Float64?               \u001b[0m\u001b[90m Float64?                           \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64?                 \u001b[0m\u001b[90m Float64?               \u001b[0m\u001b[90m Float64?           \u001b[0m\u001b[90m Float64?                        \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Float64?       \u001b[0m\u001b[90m String15?   \u001b[0m\u001b[90m Float64?           \u001b[0m\u001b[90m Float64?          \u001b[0m\u001b[90m Float64?                \u001b[0m\u001b[90m Float64?        \u001b[0m\u001b[90m Float64?         \u001b[0m\u001b[90m Float64?                  \u001b[0m\u001b[90m Float64?                       \u001b[0m\u001b[90m Float64?                      \u001b[0m\u001b[90m Float64?                            \u001b[0m\u001b[90m Float64?                   \u001b[0m\u001b[90m Float64?                              \u001b[0m\u001b[90m Float64?                       \u001b[0m\u001b[90m Float64?                                   \u001b[0m\u001b[90m Float64?         \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64?           \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Float64?       \u001b[0m\u001b[90m Float64?        \u001b[0m\u001b[90m Float64?              \u001b[0m\u001b[90m Float64?            \u001b[0m\u001b[90m Float64?       \u001b[0m\u001b[90m Float64?     \u001b[0m\u001b[90m Float64?               \u001b[0m\u001b[90m Float64?                   \u001b[0m\u001b[90m Float64?        \u001b[0m\u001b[90m Float64?                \u001b[0m\u001b[90m Float64?                             \u001b[0m\u001b[90m Float64?                    \u001b[0m\u001b[90m Float64?         \u001b[0m\u001b[90m Float64?                                \u001b[0m\n",
      "────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      1 │ AFG       Asia       Afghanistan  2020-02-24          5.0        5.0 \u001b[90m        missing     \u001b[0m\u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.125 \u001b[90m                    missing     \u001b[0m\u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m             8.33   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      2 │ AFG       Asia       Afghanistan  2020-02-25          5.0        0.0 \u001b[90m        missing     \u001b[0m\u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0   \u001b[90m                    missing     \u001b[0m\u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m             8.33   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      3 │ AFG       Asia       Afghanistan  2020-02-26          5.0        0.0 \u001b[90m        missing     \u001b[0m\u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0   \u001b[90m                    missing     \u001b[0m\u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m             8.33   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      4 │ AFG       Asia       Afghanistan  2020-02-27          5.0        0.0 \u001b[90m        missing     \u001b[0m\u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0   \u001b[90m                    missing     \u001b[0m\u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m             8.33   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      5 │ AFG       Asia       Afghanistan  2020-02-28          5.0        0.0 \u001b[90m        missing     \u001b[0m\u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0   \u001b[90m                    missing     \u001b[0m\u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m             8.33   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      6 │ AFG       Asia       Afghanistan  2020-02-29          5.0        0.0               0.714 \u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0                             0.018 \u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m             8.33   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      7 │ AFG       Asia       Afghanistan  2020-03-01          5.0        0.0               0.714 \u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0                             0.018 \u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            27.78   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      8 │ AFG       Asia       Afghanistan  2020-03-02          5.0        0.0               0.0   \u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0                             0.0   \u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            27.78   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "      9 │ AFG       Asia       Afghanistan  2020-03-03          5.0        0.0               0.0   \u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0                             0.0   \u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            27.78   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "     10 │ AFG       Asia       Afghanistan  2020-03-04          5.0        0.0               0.0   \u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0                             0.0   \u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            27.78   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "     11 │ AFG       Asia       Afghanistan  2020-03-05          5.0        0.0               0.0   \u001b[90m    missing   \u001b[0m\u001b[90m  missing   \u001b[0m\u001b[90m         missing     \u001b[0m                   0.125                  0.0                             0.0   \u001b[90m              missing     \u001b[0m\u001b[90m            missing     \u001b[0m\u001b[90m                     missing     \u001b[0m\u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            27.78   4.00995e7              54.422        18.6          2.581          1.337         1803.99 \u001b[90m       missing   \u001b[0m               597.029                 9.59 \u001b[90m      missing   \u001b[0m\u001b[90m    missing   \u001b[0m                 37.746                         0.5            64.83                    0.511 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "   ⋮    │    ⋮          ⋮           ⋮           ⋮            ⋮           ⋮              ⋮                ⋮            ⋮                ⋮                      ⋮                       ⋮                          ⋮                            ⋮                        ⋮                            ⋮                         ⋮               ⋮                   ⋮                    ⋮                    ⋮                        ⋮                            ⋮                            ⋮                             ⋮                        ⋮           ⋮                 ⋮                        ⋮                     ⋮                          ⋮                       ⋮              ⋮              ⋮               ⋮                   ⋮                     ⋮                    ⋮                ⋮                      ⋮                            ⋮                               ⋮                                 ⋮                               ⋮                                 ⋮                                  ⋮                                     ⋮                              ⋮              ⋮               ⋮               ⋮             ⋮              ⋮              ⋮                ⋮                   ⋮                     ⋮                 ⋮              ⋮                  ⋮                         ⋮                      ⋮                    ⋮                              ⋮                                 ⋮                      ⋮                             ⋮\n",
      " 208102 │ ZWE       Africa     Zimbabwe     2022-08-02     256403.0       21.0              17.0          5578.0         1.0                0.571                16031.7                    1.313                           1.063                   348.766                   0.063                            0.036               0.84 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            53.7    1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208103 │ ZWE       Africa     Zimbabwe     2022-08-03     256423.0       20.0              15.429        5579.0         1.0                0.714                16032.9                    1.251                           0.965                   348.829                   0.063                            0.045               0.86 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            53.7    1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208104 │ ZWE       Africa     Zimbabwe     2022-08-04     256444.0       21.0              15.429        5581.0         2.0                0.714                16034.2                    1.313                           0.965                   348.954                   0.125                            0.045               0.88 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            53.7    1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208105 │ ZWE       Africa     Zimbabwe     2022-08-05     256444.0        0.0               9.714        5581.0         0.0                0.571                16034.2                    0.0                             0.607                   348.954                   0.0                              0.036               0.89 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            53.7    1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208106 │ ZWE       Africa     Zimbabwe     2022-08-06     256444.0        0.0               9.714        5581.0         0.0                0.571                16034.2                    0.0                             0.607                   348.954                   0.0                              0.036               0.93 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            53.7    1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208107 │ ZWE       Africa     Zimbabwe     2022-08-07     256447.0        3.0               9.857        5584.0         3.0                1.0                  16034.4                    0.188                           0.616                   349.141                   0.188                            0.063               0.99 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m            53.7    1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208108 │ ZWE       Africa     Zimbabwe     2022-08-08     256487.0       40.0              15.0          5584.0         0.0                1.0                  16036.9                    2.501                           0.938                   349.141                   0.0                              0.063               1.04 \u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m\u001b[90m       missing    \u001b[0m  1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208109 │ ZWE       Africa     Zimbabwe     2022-08-09     256490.0        3.0              12.429        5586.0         2.0                1.143                16037.1                    0.188                           0.777                   349.266                   0.125                            0.071 \u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m\u001b[90m       missing    \u001b[0m  1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208110 │ ZWE       Africa     Zimbabwe     2022-08-10     256492.0        2.0               9.857        5587.0         1.0                1.143                16037.2                    0.125                           0.616                   349.329                   0.063                            0.071 \u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m\u001b[90m       missing    \u001b[0m  1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      " 208111 │ ZWE       Africa     Zimbabwe     2022-08-11     256513.0       21.0               9.857        5587.0         0.0                0.857                16038.6                    1.313                           0.616                   349.329                   0.0                              0.054 \u001b[90m        missing    \u001b[0m\u001b[90m      missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m                   missing \u001b[0m\u001b[90m               missing \u001b[0m\u001b[90m                           missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m                            missing \u001b[0m\u001b[90m     missing \u001b[0m\u001b[90m   missing \u001b[0m\u001b[90m                  missing \u001b[0m\u001b[90m                missing \u001b[0m\u001b[90m            missing \u001b[0m\u001b[90m                         missing \u001b[0m\u001b[90m       missing \u001b[0m\u001b[90m        missing \u001b[0m\u001b[90m missing     \u001b[0m\u001b[90m    missing         \u001b[0m\u001b[90m   missing         \u001b[0m\u001b[90m         missing         \u001b[0m\u001b[90m missing         \u001b[0m\u001b[90m        missing   \u001b[0m\u001b[90m                 missing   \u001b[0m\u001b[90m                     missing    \u001b[0m\u001b[90m                    missing    \u001b[0m\u001b[90m                          missing    \u001b[0m\u001b[90m                 missing    \u001b[0m\u001b[90m                             missing   \u001b[0m\u001b[90m                      missing   \u001b[0m\u001b[90m                                missing     \u001b[0m\u001b[90m       missing    \u001b[0m  1.59935e7              42.729        19.6          2.822          1.882         1899.78             21.4                307.846                 1.82             1.6          30.7                  36.791                         1.7            61.49                    0.571 \u001b[90m                              missing \u001b[0m\u001b[90m                     missing \u001b[0m\u001b[90m          missing \u001b[0m\u001b[90m                                 missing \u001b[0m\n",
      "\u001b[36m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            208090 rows omitted\u001b[0m"
     ]
    }
   ],
   "source": [
    "show(covid, allcols=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904268c",
   "metadata": {},
   "source": [
    "# Subsetting DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf0c30",
   "metadata": {},
   "source": [
    "## Subsetting Rows and Columns by Position\n",
    "We can take a subset of the rows and columns by specifying the index range in square brackets after the DataFrame name. There are two important things to note about indexing by row/column number:\n",
    "1. The range is 1-based\n",
    "2. The range is inclusive i.e. 1:5 returns the first to the fifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d96214f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 5 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-24</td><td>5.0</td></tr><tr><th>2</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-25</td><td>5.0</td></tr><tr><th>3</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-26</td><td>5.0</td></tr><tr><th>4</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-27</td><td>5.0</td></tr><tr><th>5</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-28</td><td>5.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases\\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & AFG & Asia & Afghanistan & 2020-02-24 & 5.0 \\\\\n",
       "\t2 & AFG & Asia & Afghanistan & 2020-02-25 & 5.0 \\\\\n",
       "\t3 & AFG & Asia & Afghanistan & 2020-02-26 & 5.0 \\\\\n",
       "\t4 & AFG & Asia & Afghanistan & 2020-02-27 & 5.0 \\\\\n",
       "\t5 & AFG & Asia & Afghanistan & 2020-02-28 & 5.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location    \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────────\n",
       "   1 │ AFG       Asia       Afghanistan  2020-02-24          5.0\n",
       "   2 │ AFG       Asia       Afghanistan  2020-02-25          5.0\n",
       "   3 │ AFG       Asia       Afghanistan  2020-02-26          5.0\n",
       "   4 │ AFG       Asia       Afghanistan  2020-02-27          5.0\n",
       "   5 │ AFG       Asia       Afghanistan  2020-02-28          5.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid[1:5, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199c728",
   "metadata": {},
   "source": [
    "We can also select columns by name, and combine this with row number indexing. We need to prefix each column name with a `:` to let Julia know that we are referring to a column name within the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37de2592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>total_cases</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>AFG</td><td>5.0</td></tr><tr><th>2</th><td>AFG</td><td>5.0</td></tr><tr><th>3</th><td>AFG</td><td>5.0</td></tr><tr><th>4</th><td>AFG</td><td>5.0</td></tr><tr><th>5</th><td>AFG</td><td>5.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& iso\\_code & total\\_cases\\\\\n",
       "\t\\hline\n",
       "\t& String15 & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & AFG & 5.0 \\\\\n",
       "\t2 & AFG & 5.0 \\\\\n",
       "\t3 & AFG & 5.0 \\\\\n",
       "\t4 & AFG & 5.0 \\\\\n",
       "\t5 & AFG & 5.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m total_cases \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m Float64?    \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │ AFG               5.0\n",
       "   2 │ AFG               5.0\n",
       "   3 │ AFG               5.0\n",
       "   4 │ AFG               5.0\n",
       "   5 │ AFG               5.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid[1:5, [:iso_code, :total_cases]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6891af47",
   "metadata": {},
   "source": [
    "## Filtering Rows by Value\n",
    "To filter rows based on their values rather than positions, we can use the `subset()` function (or `subset!()` to act in-place). This function takes the dataframe as its first argument, and the conditions as the subsequent arguments. Each condition is specified in 2 parts, separated by a `->`:\n",
    "1. The column name to filter on (preceded by a `:`) and the name to temporarily assign it to, separated by a `=>`. Note that this temporary name will **not** be used in the filtered DataFrame\n",
    "2. The condition that each row needs to satisfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b9a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:\n",
      "\u001b[1m5×3 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\n",
      "─────┼───────────────────────────────\n",
      "   1 │ Apple         200.0     false\n",
      "   2 │ Banana        175.0     false\n",
      "   3 │ Clementine    120.0     false\n",
      "   4 │ Damson         50.0     false\n",
      "   5 │ Elderberry     44.0     false\n",
      "After filtering:\n",
      "\u001b[1m3×3 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\n",
      "─────┼───────────────────────────────\n",
      "   1 │ Apple         200.0     false\n",
      "   2 │ Banana        175.0     false\n",
      "   3 │ Clementine    120.0     false"
     ]
    }
   ],
   "source": [
    "println(\"Before filtering:\")\n",
    "println(df)\n",
    "println(\"After filtering:\")\n",
    "print(subset(df, :stock => Stock -> Stock .> 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c1d47",
   "metadata": {},
   "source": [
    "The syntax of the `subset()` function from `DataFrames.jl` is quite long-winded. Luckily, the `DataFramesMeta.jl` package provides an equivalent `@subset()` function which does the same thing, but with much more intuitive syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "615b2f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering with DataFramesMeta.jl:\n",
      "\u001b[1m3×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m yellow \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m Bool   \u001b[0m\n",
      "─────┼───────────────────────────────────────\n",
      "   1 │ Apple         200.0     false   false\n",
      "   2 │ Banana        175.0     false    true\n",
      "   3 │ Clementine    120.0     false   false"
     ]
    }
   ],
   "source": [
    "println(\"After filtering with DataFramesMeta.jl:\")\n",
    "print(@subset(df, :stock .> 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd944ded",
   "metadata": {},
   "source": [
    "## Filtering Columns by Value\n",
    "Just as `subset()` allows us to select rows by their value, `transform()` allows us to select columns by their name. In the most simple case, we can select a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac40f534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>fruit</th></tr><tr><th></th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>Apple</td></tr><tr><th>2</th><td>Banana</td></tr><tr><th>3</th><td>Clementine</td></tr><tr><th>4</th><td>Damson</td></tr><tr><th>5</th><td>Elderberry</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& fruit\\\\\n",
       "\t\\hline\n",
       "\t& String\\\\\n",
       "\t\\hline\n",
       "\t1 & Apple \\\\\n",
       "\t2 & Banana \\\\\n",
       "\t3 & Clementine \\\\\n",
       "\t4 & Damson \\\\\n",
       "\t5 & Elderberry \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×1 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\n",
       "─────┼────────────\n",
       "   1 │ Apple\n",
       "   2 │ Banana\n",
       "   3 │ Clementine\n",
       "   4 │ Damson\n",
       "   5 │ Elderberry"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(df, :fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e80037",
   "metadata": {},
   "source": [
    "If we want more than one column, we **don't** need to put the column names in a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f20d3cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>fruit</th><th>stock</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>Apple</td><td>200.0</td></tr><tr><th>2</th><td>Banana</td><td>175.0</td></tr><tr><th>3</th><td>Clementine</td><td>120.0</td></tr><tr><th>4</th><td>Damson</td><td>50.0</td></tr><tr><th>5</th><td>Elderberry</td><td>44.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& fruit & stock\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Apple & 200.0 \\\\\n",
       "\t2 & Banana & 175.0 \\\\\n",
       "\t3 & Clementine & 120.0 \\\\\n",
       "\t4 & Damson & 50.0 \\\\\n",
       "\t5 & Elderberry & 44.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │ Apple         200.0\n",
       "   2 │ Banana        175.0\n",
       "   3 │ Clementine    120.0\n",
       "   4 │ Damson         50.0\n",
       "   5 │ Elderberry     44.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(df, :fruit, :stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0220a",
   "metadata": {},
   "source": [
    "We can also use regular expressions to select all columns matching a certain pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f59cdeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>fruit</th><th>stock</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>Apple</td><td>200.0</td></tr><tr><th>2</th><td>Banana</td><td>175.0</td></tr><tr><th>3</th><td>Clementine</td><td>120.0</td></tr><tr><th>4</th><td>Damson</td><td>50.0</td></tr><tr><th>5</th><td>Elderberry</td><td>44.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& fruit & stock\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Apple & 200.0 \\\\\n",
       "\t2 & Banana & 175.0 \\\\\n",
       "\t3 & Clementine & 120.0 \\\\\n",
       "\t4 & Damson & 50.0 \\\\\n",
       "\t5 & Elderberry & 44.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │ Apple         200.0\n",
       "   2 │ Banana        175.0\n",
       "   3 │ Clementine    120.0\n",
       "   4 │ Damson         50.0\n",
       "   5 │ Elderberry     44.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(df, r\"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e3f2f",
   "metadata": {},
   "source": [
    "We can take all columns **apart** from certain ones by using the `Not()` operator in combination with any of the operators outlined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26e92765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>on_offer</th></tr><tr><th></th><th title=\"Bool\">Bool</th></tr></thead><tbody><tr><th>1</th><td>0</td></tr><tr><th>2</th><td>0</td></tr><tr><th>3</th><td>0</td></tr><tr><th>4</th><td>0</td></tr><tr><th>5</th><td>0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& on\\_offer\\\\\n",
       "\t\\hline\n",
       "\t& Bool\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 \\\\\n",
       "\t2 & 0 \\\\\n",
       "\t3 & 0 \\\\\n",
       "\t4 & 0 \\\\\n",
       "\t5 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×1 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m on_offer \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Bool     \u001b[0m\n",
       "─────┼──────────\n",
       "   1 │    false\n",
       "   2 │    false\n",
       "   3 │    false\n",
       "   4 │    false\n",
       "   5 │    false"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(df, Not(r\"t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9545d",
   "metadata": {},
   "source": [
    "# Extracting DataFrame Values\n",
    "Once we have selected the rows and columns that we are interested in, we often want to extract the data held in a particular row or column e.g. to use the values in another operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26847fbd",
   "metadata": {},
   "source": [
    "## Extracting Column Values\n",
    "We can extract the values in a column as a vector using two types of notation:\n",
    "1. Specifying the name of the column with the `.` operator\n",
    "2. Using subset indexing (which also allows us to specify the number of rows to select values from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c2bd72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208111-element PooledArrays.PooledVector{String15, UInt32, Vector{UInt32}}:\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " ⋮\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\"\n",
       " \"ZWE\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid.iso_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94acca9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element PooledArrays.PooledVector{String15, UInt32, Vector{UInt32}}:\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\"\n",
       " \"AFG\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid[1:5, :iso_code]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9852eedb",
   "metadata": {},
   "source": [
    "Note that with the indexing syntax above, the column values are returned as a vector. If we want them as a one-column DataFrame instead, we wrap the column index in square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ebbe6a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th></tr><tr><th></th><th title=\"String15\">String15</th></tr></thead><tbody><tr><th>1</th><td>AFG</td></tr><tr><th>2</th><td>AFG</td></tr><tr><th>3</th><td>AFG</td></tr><tr><th>4</th><td>AFG</td></tr><tr><th>5</th><td>AFG</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& iso\\_code\\\\\n",
       "\t\\hline\n",
       "\t& String15\\\\\n",
       "\t\\hline\n",
       "\t1 & AFG \\\\\n",
       "\t2 & AFG \\\\\n",
       "\t3 & AFG \\\\\n",
       "\t4 & AFG \\\\\n",
       "\t5 & AFG \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×1 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\n",
       "─────┼──────────\n",
       "   1 │ AFG\n",
       "   2 │ AFG\n",
       "   3 │ AFG\n",
       "   4 │ AFG\n",
       "   5 │ AFG"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid[1:5, [:iso_code]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7a0af",
   "metadata": {},
   "source": [
    "## Extracting Row Values\n",
    "Julia doesn't seem to have a built-in function to extract the values in each column of a particular row to a dict, but we can define our own function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9008c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataFrameRow\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit  \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m yellow \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m Bool   \u001b[0m\n",
      "─────┼───────────────────────────────────\n",
      "   1 │ Apple     200.0     false   false\n",
      "Dict{Any, Any}(\"fruit\" => \"Apple\", \"yellow\" => false, \"stock\" => 200.0, \"on_offer\" => false)\n"
     ]
    }
   ],
   "source": [
    "function extract_df_row(df, row_index)\n",
    "    row_contents = Dict()\n",
    "    for i in enumerate(names(df))\n",
    "        row_contents[i[2]] = df[1,i[1]]\n",
    "    end\n",
    "    row_contents\n",
    "end\n",
    "\n",
    "println(df[1,:])\n",
    "\n",
    "println(extract_df_row(df, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbde96",
   "metadata": {},
   "source": [
    "# Adding DataFrame Columns\n",
    "We can add new columns to a dataframe in a number of ways, either using new data or by transforming the existing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fcd8eb",
   "metadata": {},
   "source": [
    "## Adding a Vector as a New Column\n",
    "If we have a vector with as many elements as the dataframe has rows, we can add it using the `dataframe.new_column` syntax that we saw for selecting values in an existing column. Note that this changes the dataframe in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52c0339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adding new column =\n",
      "\u001b[1m5×3 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\n",
      "─────┼───────────────────────────────\n",
      "   1 │ Apple         200.0     false\n",
      "   2 │ Banana        175.0     false\n",
      "   3 │ Clementine    120.0     false\n",
      "   4 │ Damson         50.0     false\n",
      "   5 │ Elderberry     44.0     false\n",
      "After adding new column =\n",
      "\u001b[1m5×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m yellow \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m Bool   \u001b[0m\n",
      "─────┼───────────────────────────────────────\n",
      "   1 │ Apple         200.0     false   false\n",
      "   2 │ Banana        175.0     false    true\n",
      "   3 │ Clementine    120.0     false   false\n",
      "   4 │ Damson         50.0     false   false\n",
      "   5 │ Elderberry     44.0     false   false\n"
     ]
    }
   ],
   "source": [
    "println(\"Before adding new column =\")\n",
    "println(df)\n",
    "df.yellow = [false, true, false, false, false]\n",
    "println(\"After adding new column =\")\n",
    "println(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350b174",
   "metadata": {},
   "source": [
    "## Creating New Columns from Existing Columns\n",
    "We can use the `select()` method to make new columns from existing ones. In the most simple case, we can select a column and copy its values into a new column with the `:existing_column => new_column` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cbb0682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>fruit</th><th>item</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>Apple</td><td>Apple</td></tr><tr><th>2</th><td>Banana</td><td>Banana</td></tr><tr><th>3</th><td>Clementine</td><td>Clementine</td></tr><tr><th>4</th><td>Damson</td><td>Damson</td></tr><tr><th>5</th><td>Elderberry</td><td>Elderberry</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& fruit & item\\\\\n",
       "\t\\hline\n",
       "\t& String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & Apple & Apple \\\\\n",
       "\t2 & Banana & Banana \\\\\n",
       "\t3 & Clementine & Clementine \\\\\n",
       "\t4 & Damson & Damson \\\\\n",
       "\t5 & Elderberry & Elderberry \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m item       \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m String     \u001b[0m\n",
       "─────┼────────────────────────\n",
       "   1 │ Apple       Apple\n",
       "   2 │ Banana      Banana\n",
       "   3 │ Clementine  Clementine\n",
       "   4 │ Damson      Damson\n",
       "   5 │ Elderberry  Elderberry"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(df, :fruit, :fruit => :item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131c773",
   "metadata": {},
   "source": [
    "We can also transform the values of an existing column and add the resulting values to a new column, by inserting some operations after the first `=>` operator. Note that the results of these operations need to be assigned to the new column with a second `=>` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84601b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>stock</th><th>stock_plus_one</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>200.0</td><td>201.0</td></tr><tr><th>2</th><td>175.0</td><td>176.0</td></tr><tr><th>3</th><td>120.0</td><td>121.0</td></tr><tr><th>4</th><td>50.0</td><td>51.0</td></tr><tr><th>5</th><td>44.0</td><td>45.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& stock & stock\\_plus\\_one\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 200.0 & 201.0 \\\\\n",
       "\t2 & 175.0 & 176.0 \\\\\n",
       "\t3 & 120.0 & 121.0 \\\\\n",
       "\t4 & 50.0 & 51.0 \\\\\n",
       "\t5 & 44.0 & 45.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m stock   \u001b[0m\u001b[1m stock_plus_one \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64        \u001b[0m\n",
       "─────┼─────────────────────────\n",
       "   1 │   200.0           201.0\n",
       "   2 │   175.0           176.0\n",
       "   3 │   120.0           121.0\n",
       "   4 │    50.0            51.0\n",
       "   5 │    44.0            45.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(df, :stock, :stock => (x -> x .+ 1) => :stock_plus_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb641b",
   "metadata": {},
   "source": [
    "We can do the same thing with an easier syntax with the `@select()` function from the `DataFramesMeta.jl` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b32b0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>stock</th><th>stock_plus_one</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>200.0</td><td>201.0</td></tr><tr><th>2</th><td>175.0</td><td>176.0</td></tr><tr><th>3</th><td>120.0</td><td>121.0</td></tr><tr><th>4</th><td>50.0</td><td>51.0</td></tr><tr><th>5</th><td>44.0</td><td>45.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& stock & stock\\_plus\\_one\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 200.0 & 201.0 \\\\\n",
       "\t2 & 175.0 & 176.0 \\\\\n",
       "\t3 & 120.0 & 121.0 \\\\\n",
       "\t4 & 50.0 & 51.0 \\\\\n",
       "\t5 & 44.0 & 45.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m stock   \u001b[0m\u001b[1m stock_plus_one \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64        \u001b[0m\n",
       "─────┼─────────────────────────\n",
       "   1 │   200.0           201.0\n",
       "   2 │   175.0           176.0\n",
       "   3 │   120.0           121.0\n",
       "   4 │    50.0            51.0\n",
       "   5 │    44.0            45.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@select(df, :stock, :stock_plus_one = :stock .+ 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6357ef",
   "metadata": {},
   "source": [
    "### Changing the Type of a Column\n",
    "To change a column of integers or floats to a string, we can broadcast the `string()` function across all values of the column, and assign the result as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604180b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>fruit</th><th>stock</th><th>on_offer</th><th>stock_string</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th><th title=\"Bool\">Bool</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>Apple</td><td>200.0</td><td>0</td><td>200.0</td></tr><tr><th>2</th><td>Banana</td><td>175.0</td><td>0</td><td>175.0</td></tr><tr><th>3</th><td>Clementine</td><td>120.0</td><td>0</td><td>120.0</td></tr><tr><th>4</th><td>Damson</td><td>50.0</td><td>0</td><td>50.0</td></tr><tr><th>5</th><td>Elderberry</td><td>44.0</td><td>0</td><td>44.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& fruit & stock & on\\_offer & stock\\_string\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Bool & String\\\\\n",
       "\t\\hline\n",
       "\t1 & Apple & 200.0 & 0 & 200.0 \\\\\n",
       "\t2 & Banana & 175.0 & 0 & 175.0 \\\\\n",
       "\t3 & Clementine & 120.0 & 0 & 120.0 \\\\\n",
       "\t4 & Damson & 50.0 & 0 & 50.0 \\\\\n",
       "\t5 & Elderberry & 44.0 & 0 & 44.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m stock_string \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m String       \u001b[0m\n",
       "─────┼─────────────────────────────────────────────\n",
       "   1 │ Apple         200.0     false  200.0\n",
       "   2 │ Banana        175.0     false  175.0\n",
       "   3 │ Clementine    120.0     false  120.0\n",
       "   4 │ Damson         50.0     false  50.0\n",
       "   5 │ Elderberry     44.0     false  44.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[!,:stock_string] = string.(df[!,:stock])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300b97b",
   "metadata": {},
   "source": [
    "# Split-Apply-Combine\n",
    "Many of the most common jobs in data munging follow the split-apply-combine paradigm:\n",
    "1. Split the data into chunks, where the rows in each chunk share a value of a certain column\n",
    "2. Apply an arithmetic operation to each chunk e.g. find the minimum value\n",
    "3. Combine the results of the operation performed on each chunk into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76de881",
   "metadata": {},
   "source": [
    "## Split\n",
    "We can split a dataset into chunks using the `groupby()` function. This returns a `GroupedDataFrame` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4418a525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>GroupedDataFrame with 7 groups based on key: continent</b></p><p><i>First Group (44835 rows): continent = &quot;Asia&quot;</i></p><div class=\"data-frame\"><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th><th>new_cases</th><th>new_cases_smoothed</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-24</td><td>5.0</td><td>5.0</td><td><em>missing</em></td></tr><tr><th>2</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-25</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>3</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-26</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>4</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-27</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>5</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-28</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>6</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-29</td><td>5.0</td><td>0.0</td><td>0.714</td></tr><tr><th>7</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-01</td><td>5.0</td><td>0.0</td><td>0.714</td></tr><tr><th>8</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-02</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-03</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-04</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-05</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-06</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-07</td><td>8.0</td><td>3.0</td><td>0.429</td></tr><tr><th>14</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-08</td><td>8.0</td><td>0.0</td><td>0.429</td></tr><tr><th>15</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-09</td><td>8.0</td><td>0.0</td><td>0.429</td></tr><tr><th>16</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-10</td><td>8.0</td><td>0.0</td><td>0.429</td></tr><tr><th>17</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-11</td><td>11.0</td><td>3.0</td><td>0.857</td></tr><tr><th>18</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-12</td><td>11.0</td><td>0.0</td><td>0.857</td></tr><tr><th>19</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-13</td><td>11.0</td><td>0.0</td><td>0.857</td></tr><tr><th>20</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-14</td><td>14.0</td><td>3.0</td><td>0.857</td></tr><tr><th>21</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-15</td><td>20.0</td><td>6.0</td><td>1.714</td></tr><tr><th>22</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-16</td><td>25.0</td><td>5.0</td><td>2.429</td></tr><tr><th>23</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-17</td><td>26.0</td><td>1.0</td><td>2.571</td></tr><tr><th>24</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-18</td><td>26.0</td><td>0.0</td><td>2.143</td></tr><tr><th>25</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-19</td><td>26.0</td><td>0.0</td><td>2.143</td></tr><tr><th>26</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-20</td><td>24.0</td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>27</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-21</td><td>24.0</td><td>0.0</td><td>1.714</td></tr><tr><th>28</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-22</td><td>34.0</td><td>10.0</td><td>2.286</td></tr><tr><th>29</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-23</td><td>40.0</td><td>6.0</td><td>2.429</td></tr><tr><th>30</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-24</td><td>42.0</td><td>2.0</td><td>2.571</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div><p>&vellip;</p><p><i>Last Group (14195 rows): continent = &quot;Oceania&quot;</i></p><div class=\"data-frame\"><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th><th>new_cases</th><th>new_cases_smoothed</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-01-26</td><td>4.0</td><td>4.0</td><td><em>missing</em></td></tr><tr><th>2</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-01-27</td><td>5.0</td><td>1.0</td><td><em>missing</em></td></tr><tr><th>3</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-01-28</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>4</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-01-29</td><td>6.0</td><td>1.0</td><td><em>missing</em></td></tr><tr><th>5</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-01-30</td><td>9.0</td><td>3.0</td><td><em>missing</em></td></tr><tr><th>6</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-01-31</td><td>9.0</td><td>0.0</td><td>1.286</td></tr><tr><th>7</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-01</td><td>12.0</td><td>3.0</td><td>1.714</td></tr><tr><th>8</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-02</td><td>12.0</td><td>0.0</td><td>1.143</td></tr><tr><th>9</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-03</td><td>12.0</td><td>0.0</td><td>1.0</td></tr><tr><th>10</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-04</td><td>13.0</td><td>1.0</td><td>1.143</td></tr><tr><th>11</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-05</td><td>13.0</td><td>0.0</td><td>1.0</td></tr><tr><th>12</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-06</td><td>14.0</td><td>1.0</td><td>0.714</td></tr><tr><th>13</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-07</td><td>15.0</td><td>1.0</td><td>0.857</td></tr><tr><th>14</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-08</td><td>15.0</td><td>0.0</td><td>0.429</td></tr><tr><th>15</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-09</td><td>15.0</td><td>0.0</td><td>0.429</td></tr><tr><th>16</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-10</td><td>15.0</td><td>0.0</td><td>0.429</td></tr><tr><th>17</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-11</td><td>15.0</td><td>0.0</td><td>0.286</td></tr><tr><th>18</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-12</td><td>15.0</td><td>0.0</td><td>0.286</td></tr><tr><th>19</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-13</td><td>15.0</td><td>0.0</td><td>0.143</td></tr><tr><th>20</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-14</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-15</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-16</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-17</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-18</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-19</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-20</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-21</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-22</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-23</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>AUS</td><td>Oceania</td><td>Australia</td><td>2020-02-24</td><td>15.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "GroupedDataFrame with 7 groups based on key: continent\n",
       "\n",
       "First Group (44835 rows): continent = \"Asia\"\n",
       "\n",
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases & new\\_cases & new\\_cases\\_smoothed & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64? & Float64? & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & AFG & Asia & Afghanistan & 2020-02-24 & 5.0 & 5.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & AFG & Asia & Afghanistan & 2020-02-25 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t3 & AFG & Asia & Afghanistan & 2020-02-26 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t4 & AFG & Asia & Afghanistan & 2020-02-27 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & AFG & Asia & Afghanistan & 2020-02-28 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t6 & AFG & Asia & Afghanistan & 2020-02-29 & 5.0 & 0.0 & 0.714 & $\\dots$ \\\\\n",
       "\t7 & AFG & Asia & Afghanistan & 2020-03-01 & 5.0 & 0.0 & 0.714 & $\\dots$ \\\\\n",
       "\t8 & AFG & Asia & Afghanistan & 2020-03-02 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & AFG & Asia & Afghanistan & 2020-03-03 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & AFG & Asia & Afghanistan & 2020-03-04 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & AFG & Asia & Afghanistan & 2020-03-05 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & AFG & Asia & Afghanistan & 2020-03-06 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & AFG & Asia & Afghanistan & 2020-03-07 & 8.0 & 3.0 & 0.429 & $\\dots$ \\\\\n",
       "\t14 & AFG & Asia & Afghanistan & 2020-03-08 & 8.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t15 & AFG & Asia & Afghanistan & 2020-03-09 & 8.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t16 & AFG & Asia & Afghanistan & 2020-03-10 & 8.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t17 & AFG & Asia & Afghanistan & 2020-03-11 & 11.0 & 3.0 & 0.857 & $\\dots$ \\\\\n",
       "\t18 & AFG & Asia & Afghanistan & 2020-03-12 & 11.0 & 0.0 & 0.857 & $\\dots$ \\\\\n",
       "\t19 & AFG & Asia & Afghanistan & 2020-03-13 & 11.0 & 0.0 & 0.857 & $\\dots$ \\\\\n",
       "\t20 & AFG & Asia & Afghanistan & 2020-03-14 & 14.0 & 3.0 & 0.857 & $\\dots$ \\\\\n",
       "\t21 & AFG & Asia & Afghanistan & 2020-03-15 & 20.0 & 6.0 & 1.714 & $\\dots$ \\\\\n",
       "\t22 & AFG & Asia & Afghanistan & 2020-03-16 & 25.0 & 5.0 & 2.429 & $\\dots$ \\\\\n",
       "\t23 & AFG & Asia & Afghanistan & 2020-03-17 & 26.0 & 1.0 & 2.571 & $\\dots$ \\\\\n",
       "\t24 & AFG & Asia & Afghanistan & 2020-03-18 & 26.0 & 0.0 & 2.143 & $\\dots$ \\\\\n",
       "\t25 & AFG & Asia & Afghanistan & 2020-03-19 & 26.0 & 0.0 & 2.143 & $\\dots$ \\\\\n",
       "\t26 & AFG & Asia & Afghanistan & 2020-03-20 & 24.0 & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t27 & AFG & Asia & Afghanistan & 2020-03-21 & 24.0 & 0.0 & 1.714 & $\\dots$ \\\\\n",
       "\t28 & AFG & Asia & Afghanistan & 2020-03-22 & 34.0 & 10.0 & 2.286 & $\\dots$ \\\\\n",
       "\t29 & AFG & Asia & Afghanistan & 2020-03-23 & 40.0 & 6.0 & 2.429 & $\\dots$ \\\\\n",
       "\t30 & AFG & Asia & Afghanistan & 2020-03-24 & 42.0 & 2.0 & 2.571 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "$\\dots$\n",
       "\n",
       "Last Group (14195 rows): continent = \"Oceania\"\n",
       "\n",
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases & new\\_cases & new\\_cases\\_smoothed & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64? & Float64? & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & AUS & Oceania & Australia & 2020-01-26 & 4.0 & 4.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & AUS & Oceania & Australia & 2020-01-27 & 5.0 & 1.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t3 & AUS & Oceania & Australia & 2020-01-28 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t4 & AUS & Oceania & Australia & 2020-01-29 & 6.0 & 1.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & AUS & Oceania & Australia & 2020-01-30 & 9.0 & 3.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t6 & AUS & Oceania & Australia & 2020-01-31 & 9.0 & 0.0 & 1.286 & $\\dots$ \\\\\n",
       "\t7 & AUS & Oceania & Australia & 2020-02-01 & 12.0 & 3.0 & 1.714 & $\\dots$ \\\\\n",
       "\t8 & AUS & Oceania & Australia & 2020-02-02 & 12.0 & 0.0 & 1.143 & $\\dots$ \\\\\n",
       "\t9 & AUS & Oceania & Australia & 2020-02-03 & 12.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t10 & AUS & Oceania & Australia & 2020-02-04 & 13.0 & 1.0 & 1.143 & $\\dots$ \\\\\n",
       "\t11 & AUS & Oceania & Australia & 2020-02-05 & 13.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t12 & AUS & Oceania & Australia & 2020-02-06 & 14.0 & 1.0 & 0.714 & $\\dots$ \\\\\n",
       "\t13 & AUS & Oceania & Australia & 2020-02-07 & 15.0 & 1.0 & 0.857 & $\\dots$ \\\\\n",
       "\t14 & AUS & Oceania & Australia & 2020-02-08 & 15.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t15 & AUS & Oceania & Australia & 2020-02-09 & 15.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t16 & AUS & Oceania & Australia & 2020-02-10 & 15.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t17 & AUS & Oceania & Australia & 2020-02-11 & 15.0 & 0.0 & 0.286 & $\\dots$ \\\\\n",
       "\t18 & AUS & Oceania & Australia & 2020-02-12 & 15.0 & 0.0 & 0.286 & $\\dots$ \\\\\n",
       "\t19 & AUS & Oceania & Australia & 2020-02-13 & 15.0 & 0.0 & 0.143 & $\\dots$ \\\\\n",
       "\t20 & AUS & Oceania & Australia & 2020-02-14 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & AUS & Oceania & Australia & 2020-02-15 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & AUS & Oceania & Australia & 2020-02-16 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & AUS & Oceania & Australia & 2020-02-17 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & AUS & Oceania & Australia & 2020-02-18 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & AUS & Oceania & Australia & 2020-02-19 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & AUS & Oceania & Australia & 2020-02-20 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & AUS & Oceania & Australia & 2020-02-21 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & AUS & Oceania & Australia & 2020-02-22 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & AUS & Oceania & Australia & 2020-02-23 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & AUS & Oceania & Australia & 2020-02-24 & 15.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "GroupedDataFrame with 7 groups based on key: continent\n",
       "First Group (44835 rows): continent = \"Asia\"\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location    \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_cases \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │ AFG       Asia       Afghanistan  2020-02-24          5.0        5.0 \u001b[90m\u001b[0m ⋯\n",
       "     2 │ AFG       Asia       Afghanistan  2020-02-25          5.0        0.0 \u001b[90m\u001b[0m\n",
       "     3 │ AFG       Asia       Afghanistan  2020-02-26          5.0        0.0 \u001b[90m\u001b[0m\n",
       "     4 │ AFG       Asia       Afghanistan  2020-02-27          5.0        0.0 \u001b[90m\u001b[0m\n",
       "     5 │ AFG       Asia       Afghanistan  2020-02-28          5.0        0.0 \u001b[90m\u001b[0m ⋯\n",
       "     6 │ AFG       Asia       Afghanistan  2020-02-29          5.0        0.0\n",
       "     7 │ AFG       Asia       Afghanistan  2020-03-01          5.0        0.0\n",
       "     8 │ AFG       Asia       Afghanistan  2020-03-02          5.0        0.0\n",
       "     9 │ AFG       Asia       Afghanistan  2020-03-03          5.0        0.0  ⋯\n",
       "    10 │ AFG       Asia       Afghanistan  2020-03-04          5.0        0.0\n",
       "    11 │ AFG       Asia       Afghanistan  2020-03-05          5.0        0.0\n",
       "   ⋮   │    ⋮          ⋮           ⋮           ⋮            ⋮           ⋮      ⋱\n",
       " 44825 │ YEM       Asia       Yemen        2022-08-01      11877.0        0.0\n",
       " 44826 │ YEM       Asia       Yemen        2022-08-02      11877.0        0.0  ⋯\n",
       " 44827 │ YEM       Asia       Yemen        2022-08-03      11877.0        0.0\n",
       " 44828 │ YEM       Asia       Yemen        2022-08-04      11895.0       18.0\n",
       " 44829 │ YEM       Asia       Yemen        2022-08-05      11895.0        0.0\n",
       " 44830 │ YEM       Asia       Yemen        2022-08-06      11895.0        0.0  ⋯\n",
       " 44831 │ YEM       Asia       Yemen        2022-08-07      11895.0        0.0\n",
       " 44832 │ YEM       Asia       Yemen        2022-08-08      11903.0        8.0\n",
       " 44833 │ YEM       Asia       Yemen        2022-08-09      11903.0        0.0\n",
       " 44834 │ YEM       Asia       Yemen        2022-08-10      11903.0        0.0  ⋯\n",
       " 44835 │ YEM       Asia       Yemen        2022-08-11      11903.0        0.0\n",
       "\u001b[36m                                               61 columns and 44813 rows omitted\u001b[0m\n",
       "⋮\n",
       "Last Group (14195 rows): continent = \"Oceania\"\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location          \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String            \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │ AUS       Oceania    Australia          2020-01-26          4.0       ⋯\n",
       "     2 │ AUS       Oceania    Australia          2020-01-27          5.0\n",
       "     3 │ AUS       Oceania    Australia          2020-01-28          5.0\n",
       "     4 │ AUS       Oceania    Australia          2020-01-29          6.0\n",
       "     5 │ AUS       Oceania    Australia          2020-01-30          9.0       ⋯\n",
       "     6 │ AUS       Oceania    Australia          2020-01-31          9.0\n",
       "     7 │ AUS       Oceania    Australia          2020-02-01         12.0\n",
       "     8 │ AUS       Oceania    Australia          2020-02-02         12.0\n",
       "     9 │ AUS       Oceania    Australia          2020-02-03         12.0       ⋯\n",
       "    10 │ AUS       Oceania    Australia          2020-02-04         13.0\n",
       "    11 │ AUS       Oceania    Australia          2020-02-05         13.0\n",
       "   ⋮   │    ⋮          ⋮              ⋮              ⋮            ⋮            ⋱\n",
       " 14185 │ WLF       Oceania    Wallis and Futuna  2022-08-01        761.0\n",
       " 14186 │ WLF       Oceania    Wallis and Futuna  2022-08-02        761.0       ⋯\n",
       " 14187 │ WLF       Oceania    Wallis and Futuna  2022-08-03        761.0\n",
       " 14188 │ WLF       Oceania    Wallis and Futuna  2022-08-04        761.0\n",
       " 14189 │ WLF       Oceania    Wallis and Futuna  2022-08-05        761.0\n",
       " 14190 │ WLF       Oceania    Wallis and Futuna  2022-08-06        761.0       ⋯\n",
       " 14191 │ WLF       Oceania    Wallis and Futuna  2022-08-07        761.0\n",
       " 14192 │ WLF       Oceania    Wallis and Futuna  2022-08-08        761.0\n",
       " 14193 │ WLF       Oceania    Wallis and Futuna  2022-08-09        761.0\n",
       " 14194 │ WLF       Oceania    Wallis and Futuna  2022-08-10        761.0       ⋯\n",
       " 14195 │ WLF       Oceania    Wallis and Futuna  2022-08-11        761.0\n",
       "\u001b[36m                                               62 columns and 14173 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby(covid, :continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c254710",
   "metadata": {},
   "source": [
    "We can group by as many columns as we want, but we must pass the columns as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c38949e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>GroupedDataFrame with 244 groups based on keys: continent, location</b></p><p><i>First Group (900 rows): continent = &quot;Asia&quot;, location = &quot;Afghanistan&quot;</i></p><div class=\"data-frame\"><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th><th>new_cases</th><th>new_cases_smoothed</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-24</td><td>5.0</td><td>5.0</td><td><em>missing</em></td></tr><tr><th>2</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-25</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>3</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-26</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>4</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-27</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>5</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-28</td><td>5.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>6</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-02-29</td><td>5.0</td><td>0.0</td><td>0.714</td></tr><tr><th>7</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-01</td><td>5.0</td><td>0.0</td><td>0.714</td></tr><tr><th>8</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-02</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-03</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-04</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-05</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-06</td><td>5.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-07</td><td>8.0</td><td>3.0</td><td>0.429</td></tr><tr><th>14</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-08</td><td>8.0</td><td>0.0</td><td>0.429</td></tr><tr><th>15</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-09</td><td>8.0</td><td>0.0</td><td>0.429</td></tr><tr><th>16</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-10</td><td>8.0</td><td>0.0</td><td>0.429</td></tr><tr><th>17</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-11</td><td>11.0</td><td>3.0</td><td>0.857</td></tr><tr><th>18</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-12</td><td>11.0</td><td>0.0</td><td>0.857</td></tr><tr><th>19</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-13</td><td>11.0</td><td>0.0</td><td>0.857</td></tr><tr><th>20</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-14</td><td>14.0</td><td>3.0</td><td>0.857</td></tr><tr><th>21</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-15</td><td>20.0</td><td>6.0</td><td>1.714</td></tr><tr><th>22</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-16</td><td>25.0</td><td>5.0</td><td>2.429</td></tr><tr><th>23</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-17</td><td>26.0</td><td>1.0</td><td>2.571</td></tr><tr><th>24</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-18</td><td>26.0</td><td>0.0</td><td>2.143</td></tr><tr><th>25</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-19</td><td>26.0</td><td>0.0</td><td>2.143</td></tr><tr><th>26</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-20</td><td>24.0</td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>27</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-21</td><td>24.0</td><td>0.0</td><td>1.714</td></tr><tr><th>28</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-22</td><td>34.0</td><td>10.0</td><td>2.286</td></tr><tr><th>29</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-23</td><td>40.0</td><td>6.0</td><td>2.429</td></tr><tr><th>30</th><td>AFG</td><td>Asia</td><td>Afghanistan</td><td>2020-03-24</td><td>42.0</td><td>2.0</td><td>2.571</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div><p>&vellip;</p><p><i>Last Group (662 rows): continent = &quot;Oceania&quot;, location = &quot;Wallis and Futuna&quot;</i></p><div class=\"data-frame\"><table class=\"data-frame\"><thead><tr><th></th><th>iso_code</th><th>continent</th><th>location</th><th>date</th><th>total_cases</th><th>new_cases</th><th>new_cases_smoothed</th></tr><tr><th></th><th title=\"String15\">String15</th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"String\">String</th><th title=\"Dates.Date\">Date</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-19</td><td>1.0</td><td>1.0</td><td><em>missing</em></td></tr><tr><th>2</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-20</td><td>1.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>3</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-21</td><td>1.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>4</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-22</td><td>1.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>5</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-23</td><td>1.0</td><td>0.0</td><td><em>missing</em></td></tr><tr><th>6</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-24</td><td>1.0</td><td>0.0</td><td>0.143</td></tr><tr><th>7</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-25</td><td>1.0</td><td>0.0</td><td>0.143</td></tr><tr><th>8</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-26</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-27</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-28</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-29</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-30</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-10-31</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-01</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-02</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-03</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-04</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-05</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-06</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-07</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-08</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-09</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-10</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-11</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-12</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-13</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-14</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-15</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-16</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>WLF</td><td>Oceania</td><td>Wallis and Futuna</td><td>2020-11-17</td><td>2.0</td><td>1.0</td><td>0.143</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "GroupedDataFrame with 244 groups based on keys: continent, location\n",
       "\n",
       "First Group (900 rows): continent = \"Asia\", location = \"Afghanistan\"\n",
       "\n",
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases & new\\_cases & new\\_cases\\_smoothed & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64? & Float64? & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & AFG & Asia & Afghanistan & 2020-02-24 & 5.0 & 5.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & AFG & Asia & Afghanistan & 2020-02-25 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t3 & AFG & Asia & Afghanistan & 2020-02-26 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t4 & AFG & Asia & Afghanistan & 2020-02-27 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & AFG & Asia & Afghanistan & 2020-02-28 & 5.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t6 & AFG & Asia & Afghanistan & 2020-02-29 & 5.0 & 0.0 & 0.714 & $\\dots$ \\\\\n",
       "\t7 & AFG & Asia & Afghanistan & 2020-03-01 & 5.0 & 0.0 & 0.714 & $\\dots$ \\\\\n",
       "\t8 & AFG & Asia & Afghanistan & 2020-03-02 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & AFG & Asia & Afghanistan & 2020-03-03 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & AFG & Asia & Afghanistan & 2020-03-04 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & AFG & Asia & Afghanistan & 2020-03-05 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & AFG & Asia & Afghanistan & 2020-03-06 & 5.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & AFG & Asia & Afghanistan & 2020-03-07 & 8.0 & 3.0 & 0.429 & $\\dots$ \\\\\n",
       "\t14 & AFG & Asia & Afghanistan & 2020-03-08 & 8.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t15 & AFG & Asia & Afghanistan & 2020-03-09 & 8.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t16 & AFG & Asia & Afghanistan & 2020-03-10 & 8.0 & 0.0 & 0.429 & $\\dots$ \\\\\n",
       "\t17 & AFG & Asia & Afghanistan & 2020-03-11 & 11.0 & 3.0 & 0.857 & $\\dots$ \\\\\n",
       "\t18 & AFG & Asia & Afghanistan & 2020-03-12 & 11.0 & 0.0 & 0.857 & $\\dots$ \\\\\n",
       "\t19 & AFG & Asia & Afghanistan & 2020-03-13 & 11.0 & 0.0 & 0.857 & $\\dots$ \\\\\n",
       "\t20 & AFG & Asia & Afghanistan & 2020-03-14 & 14.0 & 3.0 & 0.857 & $\\dots$ \\\\\n",
       "\t21 & AFG & Asia & Afghanistan & 2020-03-15 & 20.0 & 6.0 & 1.714 & $\\dots$ \\\\\n",
       "\t22 & AFG & Asia & Afghanistan & 2020-03-16 & 25.0 & 5.0 & 2.429 & $\\dots$ \\\\\n",
       "\t23 & AFG & Asia & Afghanistan & 2020-03-17 & 26.0 & 1.0 & 2.571 & $\\dots$ \\\\\n",
       "\t24 & AFG & Asia & Afghanistan & 2020-03-18 & 26.0 & 0.0 & 2.143 & $\\dots$ \\\\\n",
       "\t25 & AFG & Asia & Afghanistan & 2020-03-19 & 26.0 & 0.0 & 2.143 & $\\dots$ \\\\\n",
       "\t26 & AFG & Asia & Afghanistan & 2020-03-20 & 24.0 & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t27 & AFG & Asia & Afghanistan & 2020-03-21 & 24.0 & 0.0 & 1.714 & $\\dots$ \\\\\n",
       "\t28 & AFG & Asia & Afghanistan & 2020-03-22 & 34.0 & 10.0 & 2.286 & $\\dots$ \\\\\n",
       "\t29 & AFG & Asia & Afghanistan & 2020-03-23 & 40.0 & 6.0 & 2.429 & $\\dots$ \\\\\n",
       "\t30 & AFG & Asia & Afghanistan & 2020-03-24 & 42.0 & 2.0 & 2.571 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "$\\dots$\n",
       "\n",
       "Last Group (662 rows): continent = \"Oceania\", location = \"Wallis and Futuna\"\n",
       "\n",
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& iso\\_code & continent & location & date & total\\_cases & new\\_cases & new\\_cases\\_smoothed & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String15? & String & Date & Float64? & Float64? & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & WLF & Oceania & Wallis and Futuna & 2020-10-19 & 1.0 & 1.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & WLF & Oceania & Wallis and Futuna & 2020-10-20 & 1.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t3 & WLF & Oceania & Wallis and Futuna & 2020-10-21 & 1.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t4 & WLF & Oceania & Wallis and Futuna & 2020-10-22 & 1.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & WLF & Oceania & Wallis and Futuna & 2020-10-23 & 1.0 & 0.0 & \\emph{missing} & $\\dots$ \\\\\n",
       "\t6 & WLF & Oceania & Wallis and Futuna & 2020-10-24 & 1.0 & 0.0 & 0.143 & $\\dots$ \\\\\n",
       "\t7 & WLF & Oceania & Wallis and Futuna & 2020-10-25 & 1.0 & 0.0 & 0.143 & $\\dots$ \\\\\n",
       "\t8 & WLF & Oceania & Wallis and Futuna & 2020-10-26 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & WLF & Oceania & Wallis and Futuna & 2020-10-27 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & WLF & Oceania & Wallis and Futuna & 2020-10-28 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & WLF & Oceania & Wallis and Futuna & 2020-10-29 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & WLF & Oceania & Wallis and Futuna & 2020-10-30 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & WLF & Oceania & Wallis and Futuna & 2020-10-31 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & WLF & Oceania & Wallis and Futuna & 2020-11-01 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & WLF & Oceania & Wallis and Futuna & 2020-11-02 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & WLF & Oceania & Wallis and Futuna & 2020-11-03 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & WLF & Oceania & Wallis and Futuna & 2020-11-04 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & WLF & Oceania & Wallis and Futuna & 2020-11-05 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & WLF & Oceania & Wallis and Futuna & 2020-11-06 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & WLF & Oceania & Wallis and Futuna & 2020-11-07 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & WLF & Oceania & Wallis and Futuna & 2020-11-08 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & WLF & Oceania & Wallis and Futuna & 2020-11-09 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & WLF & Oceania & Wallis and Futuna & 2020-11-10 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & WLF & Oceania & Wallis and Futuna & 2020-11-11 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & WLF & Oceania & Wallis and Futuna & 2020-11-12 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & WLF & Oceania & Wallis and Futuna & 2020-11-13 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & WLF & Oceania & Wallis and Futuna & 2020-11-14 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & WLF & Oceania & Wallis and Futuna & 2020-11-15 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & WLF & Oceania & Wallis and Futuna & 2020-11-16 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & WLF & Oceania & Wallis and Futuna & 2020-11-17 & 2.0 & 1.0 & 0.143 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "GroupedDataFrame with 244 groups based on keys: continent, location\n",
       "First Group (900 rows): continent = \"Asia\", location = \"Afghanistan\"\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location    \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_cases \u001b[0m\u001b[1m n\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ AFG       Asia       Afghanistan  2020-02-24          5.0        5.0 \u001b[90m  \u001b[0m ⋯\n",
       "   2 │ AFG       Asia       Afghanistan  2020-02-25          5.0        0.0 \u001b[90m\u001b[0m\n",
       "   3 │ AFG       Asia       Afghanistan  2020-02-26          5.0        0.0 \u001b[90m\u001b[0m\n",
       "   4 │ AFG       Asia       Afghanistan  2020-02-27          5.0        0.0 \u001b[90m\u001b[0m\n",
       "   5 │ AFG       Asia       Afghanistan  2020-02-28          5.0        0.0 \u001b[90m  \u001b[0m ⋯\n",
       "   6 │ AFG       Asia       Afghanistan  2020-02-29          5.0        0.0\n",
       "   7 │ AFG       Asia       Afghanistan  2020-03-01          5.0        0.0\n",
       "   8 │ AFG       Asia       Afghanistan  2020-03-02          5.0        0.0\n",
       "   9 │ AFG       Asia       Afghanistan  2020-03-03          5.0        0.0    ⋯\n",
       "  10 │ AFG       Asia       Afghanistan  2020-03-04          5.0        0.0\n",
       "  11 │ AFG       Asia       Afghanistan  2020-03-05          5.0        0.0\n",
       "  ⋮  │    ⋮          ⋮           ⋮           ⋮            ⋮           ⋮        ⋱\n",
       " 890 │ AFG       Asia       Afghanistan  2022-08-01     185930.0      181.0\n",
       " 891 │ AFG       Asia       Afghanistan  2022-08-02     186120.0      190.0    ⋯\n",
       " 892 │ AFG       Asia       Afghanistan  2022-08-03     186393.0      273.0\n",
       " 893 │ AFG       Asia       Afghanistan  2022-08-04     186697.0      304.0\n",
       " 894 │ AFG       Asia       Afghanistan  2022-08-05     187037.0      340.0\n",
       " 895 │ AFG       Asia       Afghanistan  2022-08-06     187109.0       72.0    ⋯\n",
       " 896 │ AFG       Asia       Afghanistan  2022-08-07     187442.0      333.0\n",
       " 897 │ AFG       Asia       Afghanistan  2022-08-08     187685.0      243.0\n",
       " 898 │ AFG       Asia       Afghanistan  2022-08-09     187966.0      281.0\n",
       " 899 │ AFG       Asia       Afghanistan  2022-08-10     188202.0      236.0    ⋯\n",
       " 900 │ AFG       Asia       Afghanistan  2022-08-11     188506.0      304.0\n",
       "\u001b[36m                                                 61 columns and 878 rows omitted\u001b[0m\n",
       "⋮\n",
       "Last Group (662 rows): continent = \"Oceania\", location = \"Wallis and Futuna\"\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m iso_code \u001b[0m\u001b[1m continent \u001b[0m\u001b[1m location          \u001b[0m\u001b[1m date       \u001b[0m\u001b[1m total_cases \u001b[0m\u001b[1m new_ca\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String            \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Float64?    \u001b[0m\u001b[90m Float6\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ WLF       Oceania    Wallis and Futuna  2020-10-19          1.0         ⋯\n",
       "   2 │ WLF       Oceania    Wallis and Futuna  2020-10-20          1.0\n",
       "   3 │ WLF       Oceania    Wallis and Futuna  2020-10-21          1.0\n",
       "   4 │ WLF       Oceania    Wallis and Futuna  2020-10-22          1.0\n",
       "   5 │ WLF       Oceania    Wallis and Futuna  2020-10-23          1.0         ⋯\n",
       "   6 │ WLF       Oceania    Wallis and Futuna  2020-10-24          1.0\n",
       "   7 │ WLF       Oceania    Wallis and Futuna  2020-10-25          1.0\n",
       "   8 │ WLF       Oceania    Wallis and Futuna  2020-10-26          1.0\n",
       "   9 │ WLF       Oceania    Wallis and Futuna  2020-10-27          1.0         ⋯\n",
       "  10 │ WLF       Oceania    Wallis and Futuna  2020-10-28          1.0\n",
       "  11 │ WLF       Oceania    Wallis and Futuna  2020-10-29          1.0\n",
       "  ⋮  │    ⋮          ⋮              ⋮              ⋮            ⋮           ⋮  ⋱\n",
       " 652 │ WLF       Oceania    Wallis and Futuna  2022-08-01        761.0\n",
       " 653 │ WLF       Oceania    Wallis and Futuna  2022-08-02        761.0         ⋯\n",
       " 654 │ WLF       Oceania    Wallis and Futuna  2022-08-03        761.0\n",
       " 655 │ WLF       Oceania    Wallis and Futuna  2022-08-04        761.0\n",
       " 656 │ WLF       Oceania    Wallis and Futuna  2022-08-05        761.0\n",
       " 657 │ WLF       Oceania    Wallis and Futuna  2022-08-06        761.0         ⋯\n",
       " 658 │ WLF       Oceania    Wallis and Futuna  2022-08-07        761.0\n",
       " 659 │ WLF       Oceania    Wallis and Futuna  2022-08-08        761.0\n",
       " 660 │ WLF       Oceania    Wallis and Futuna  2022-08-09        761.0\n",
       " 661 │ WLF       Oceania    Wallis and Futuna  2022-08-10        761.0         ⋯\n",
       " 662 │ WLF       Oceania    Wallis and Futuna  2022-08-11        761.0\n",
       "\u001b[36m                                                 62 columns and 640 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby(covid, [:continent, :location])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567f03b",
   "metadata": {},
   "source": [
    "## Apply & Combine\n",
    "Once we have a `GroupedDataFrame` object, we can perform operations on each group. We can do this with the `@combine()` macro from `DataFramesMeta.jl`, where the first argument is the name of the `GroupedDataFrame`, and the subsequent arguments are operation specifications. Each operation is specified with the new column name first, then the `=` operator, then the function to be applied to the values in a specific column. When applying these operations, we can skip missing values in each group by wrapping the column in a `skipmissing()` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99da6f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>7 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>continent</th><th>highest_daily_cases</th></tr><tr><th></th><th title=\"Union{Missing, String15}\">String15?</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>Asia</td><td>621317.0</td></tr><tr><th>2</th><td><em>missing</em></td><td>4.07921e6</td></tr><tr><th>3</th><td>Europe</td><td>527487.0</td></tr><tr><th>4</th><td>Africa</td><td>41576.0</td></tr><tr><th>5</th><td>North America</td><td>1.38391e6</td></tr><tr><th>6</th><td>South America</td><td>287149.0</td></tr><tr><th>7</th><td>Oceania</td><td>175271.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& continent & highest\\_daily\\_cases\\\\\n",
       "\t\\hline\n",
       "\t& String15? & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Asia & 621317.0 \\\\\n",
       "\t2 & \\emph{missing} & 4.07921e6 \\\\\n",
       "\t3 & Europe & 527487.0 \\\\\n",
       "\t4 & Africa & 41576.0 \\\\\n",
       "\t5 & North America & 1.38391e6 \\\\\n",
       "\t6 & South America & 287149.0 \\\\\n",
       "\t7 & Oceania & 175271.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m7×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m continent     \u001b[0m\u001b[1m highest_daily_cases \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15?     \u001b[0m\u001b[90m Float64             \u001b[0m\n",
       "─────┼────────────────────────────────────\n",
       "   1 │ Asia                621317.0\n",
       "   2 │\u001b[90m missing       \u001b[0m           4.07921e6\n",
       "   3 │ Europe              527487.0\n",
       "   4 │ Africa               41576.0\n",
       "   5 │ North America            1.38391e6\n",
       "   6 │ South America       287149.0\n",
       "   7 │ Oceania             175271.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_continents = groupby(covid, :continent)\n",
    "@combine(covid_continents, :highest_daily_cases = maximum(skipmissing(:new_cases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49302de2",
   "metadata": {},
   "source": [
    "# Joining DataFrames\n",
    "We can do the same range of joins with Julia `DataFrames` as we can in Python and R (inner, outer, left, right etc). For each function, we specify the column to use for joining with the `on` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3831c0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>Job</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>20</td><td>Lawyer</td></tr><tr><th>2</th><td>40</td><td>Doctor</td></tr><tr><th>3</th><td>80</td><td>Zoologist</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& ID & Job\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 20 & Lawyer \\\\\n",
       "\t2 & 40 & Doctor \\\\\n",
       "\t3 & 80 & Zoologist \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m Job       \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String    \u001b[0m\n",
       "─────┼──────────────────\n",
       "   1 │    20  Lawyer\n",
       "   2 │    40  Doctor\n",
       "   3 │    80  Zoologist"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = DataFrame(ID=[20, 40, 60], Name=[\"John Doe\", \"Jane Doe\", \"Julia Doe\"])\n",
    "jobs = DataFrame(ID=[20, 40, 80], Job=[\"Lawyer\", \"Doctor\", \"Zoologist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e635d26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>2 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>Name</th><th>Job</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String\">String</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>20</td><td>John Doe</td><td>Lawyer</td></tr><tr><th>2</th><td>40</td><td>Jane Doe</td><td>Doctor</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ID & Name & Job\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 20 & John Doe & Lawyer \\\\\n",
       "\t2 & 40 & Jane Doe & Doctor \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m Name     \u001b[0m\u001b[1m Job    \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String   \u001b[0m\u001b[90m String \u001b[0m\n",
       "─────┼─────────────────────────\n",
       "   1 │    20  John Doe  Lawyer\n",
       "   2 │    40  Jane Doe  Doctor"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "innerjoin(people, jobs, on=:ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a49947df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>4 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>Name</th><th>Job</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Union{Missing, String}\">String?</th><th title=\"Union{Missing, String}\">String?</th></tr></thead><tbody><tr><th>1</th><td>20</td><td>John Doe</td><td>Lawyer</td></tr><tr><th>2</th><td>40</td><td>Jane Doe</td><td>Doctor</td></tr><tr><th>3</th><td>60</td><td>Julia Doe</td><td><em>missing</em></td></tr><tr><th>4</th><td>80</td><td><em>missing</em></td><td>Zoologist</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ID & Name & Job\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String? & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 20 & John Doe & Lawyer \\\\\n",
       "\t2 & 40 & Jane Doe & Doctor \\\\\n",
       "\t3 & 60 & Julia Doe & \\emph{missing} \\\\\n",
       "\t4 & 80 & \\emph{missing} & Zoologist \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m Name      \u001b[0m\u001b[1m Job       \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String?   \u001b[0m\u001b[90m String?   \u001b[0m\n",
       "─────┼─────────────────────────────\n",
       "   1 │    20  John Doe   Lawyer\n",
       "   2 │    40  Jane Doe   Doctor\n",
       "   3 │    60  Julia Doe \u001b[90m missing   \u001b[0m\n",
       "   4 │    80 \u001b[90m missing   \u001b[0m Zoologist"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outerjoin(people, jobs, on=:ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "26c9219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>Name</th><th>Job</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String\">String</th><th title=\"Union{Missing, String}\">String?</th></tr></thead><tbody><tr><th>1</th><td>20</td><td>John Doe</td><td>Lawyer</td></tr><tr><th>2</th><td>40</td><td>Jane Doe</td><td>Doctor</td></tr><tr><th>3</th><td>60</td><td>Julia Doe</td><td><em>missing</em></td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ID & Name & Job\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 20 & John Doe & Lawyer \\\\\n",
       "\t2 & 40 & Jane Doe & Doctor \\\\\n",
       "\t3 & 60 & Julia Doe & \\emph{missing} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m Name      \u001b[0m\u001b[1m Job     \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m String? \u001b[0m\n",
       "─────┼───────────────────────────\n",
       "   1 │    20  John Doe   Lawyer\n",
       "   2 │    40  Jane Doe   Doctor\n",
       "   3 │    60  Julia Doe \u001b[90m missing \u001b[0m"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftjoin(people, jobs, on=:ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd289dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>Name</th><th>Job</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Union{Missing, String}\">String?</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>20</td><td>John Doe</td><td>Lawyer</td></tr><tr><th>2</th><td>40</td><td>Jane Doe</td><td>Doctor</td></tr><tr><th>3</th><td>80</td><td><em>missing</em></td><td>Zoologist</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ID & Name & Job\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String? & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 20 & John Doe & Lawyer \\\\\n",
       "\t2 & 40 & Jane Doe & Doctor \\\\\n",
       "\t3 & 80 & \\emph{missing} & Zoologist \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m Name     \u001b[0m\u001b[1m Job       \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String?  \u001b[0m\u001b[90m String    \u001b[0m\n",
       "─────┼────────────────────────────\n",
       "   1 │    20  John Doe  Lawyer\n",
       "   2 │    40  Jane Doe  Doctor\n",
       "   3 │    80 \u001b[90m missing  \u001b[0m Zoologist"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightjoin(people, jobs, on=:ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7c71c",
   "metadata": {},
   "source": [
    "# Sorting DataFrames\n",
    "The `DataFramesMeta.jl` package provides the `@orderby()` macro to sort a DataFrame by the values in a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb4e2528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sorting =\n",
      "\u001b[1m5×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m yellow \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m Bool   \u001b[0m\n",
      "─────┼───────────────────────────────────────\n",
      "   1 │ Apple         200.0     false   false\n",
      "   2 │ Banana        175.0     false    true\n",
      "   3 │ Clementine    120.0     false   false\n",
      "   4 │ Damson         50.0     false   false\n",
      "   5 │ Elderberry     44.0     false   false\n",
      "After sorting =\n",
      "\u001b[1m5×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m yellow \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m Bool   \u001b[0m\n",
      "─────┼───────────────────────────────────────\n",
      "   1 │ Elderberry     44.0     false   false\n",
      "   2 │ Damson         50.0     false   false\n",
      "   3 │ Clementine    120.0     false   false\n",
      "   4 │ Banana        175.0     false    true\n",
      "   5 │ Apple         200.0     false   false\n"
     ]
    }
   ],
   "source": [
    "println(\"Before sorting =\")\n",
    "println(df)\n",
    "println(\"After sorting =\")\n",
    "println(@orderby(df, :stock))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fbd41",
   "metadata": {},
   "source": [
    "By default, numeric values are sorted in descending order, but we can reverse this ordering by putting the `-` operator before the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "08474367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sorting by descending order =\n",
      "\u001b[1m5×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m fruit      \u001b[0m\u001b[1m stock   \u001b[0m\u001b[1m on_offer \u001b[0m\u001b[1m yellow \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Bool     \u001b[0m\u001b[90m Bool   \u001b[0m\n",
      "─────┼───────────────────────────────────────\n",
      "   1 │ Apple         200.0     false   false\n",
      "   2 │ Banana        175.0     false    true\n",
      "   3 │ Clementine    120.0     false   false\n",
      "   4 │ Damson         50.0     false   false\n",
      "   5 │ Elderberry     44.0     false   false\n"
     ]
    }
   ],
   "source": [
    "println(\"After sorting by stock in descending order =\")\n",
    "println(@orderby(df, -:stock))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0b322",
   "metadata": {},
   "source": [
    "# Piping DataFrame Commands\n",
    "Just as dplyr in R has the `%>%` operator to pipe the output of one command to the next, so the `Pipe` package provides us with the `|>` operator. Note that in contrast to dplyr, the output of the last command is not silently passed to the next command; instead, the output of the operation to the left of `|>` must be explicitly referenced as `_` in the next function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dcc1054d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>2 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>yellow</th><th>highest_stock</th></tr><tr><th></th><th title=\"Bool\">Bool</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>175.0</td></tr><tr><th>2</th><td>0</td><td>200.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& yellow & highest\\_stock\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 175.0 \\\\\n",
       "\t2 & 0 & 200.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m yellow \u001b[0m\u001b[1m highest_stock \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Bool   \u001b[0m\u001b[90m Float64       \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │   true          175.0\n",
       "   2 │  false          200.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pipe df |>\n",
    "    select(_, :fruit, :stock, :yellow) |>\n",
    "    groupby(_, :yellow) |>\n",
    "    @combine(_, :highest_stock = maximum(:stock)) |>\n",
    "    @orderby(_, :highest_stock)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
